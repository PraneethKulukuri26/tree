{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92e15829",
   "metadata": {},
   "source": [
    "\n",
    "# Enhanced QAOA Portfolio Optimization — Advanced Features\n",
    "This notebook is an enhanced, hackathon-ready QAOA portfolio optimization demo. Additions over the basic model:\n",
    "- **Ledoit–Wolf shrinkage** for covariance (robust Sigma estimate)\n",
    "- **Black–Litterman** (optional) to blend prior returns with views / market caps\n",
    "- **Discrete weights** encoding (binary fixed-point) or simple selection encoding\n",
    "- **Sector caps**, **cardinality**, and **turnover** penalties in QUBO\n",
    "- **Warm-start** hinting and guidance for custom XY-mixers (implementation notes)\n",
    "- **Dinkelbach** loop to convert Sharpe ratio into quadratic subproblems\n",
    "- **Subset tangency** refinement and transaction-cost-aware Sharpe evaluation\n",
    "\n",
    "Run this in a clean Python 3.10/3.11 environment (conda env recommended). If using Colab, uncomment the pip install line in the first code cell.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c990f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Colab / first-run installs (uncomment if needed)\n",
    "# !pip install -q qiskit==1.2.4 qiskit-optimization==0.6.1 qiskit-aer==0.13.3 docplex==2.25.236 yfinance numpy pandas scipy matplotlib\n",
    "\n",
    "# Standard imports\n",
    "import numpy as np, pandas as pd, math, warnings, os\n",
    "from typing import List, Tuple, Dict, Optional\n",
    "warnings.filterwarnings('ignore')\n",
    "np.set_printoptions(precision=4, suppress=True)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Qiskit imports\n",
    "from qiskit.primitives import Sampler\n",
    "from qiskit_algorithms import QAOA\n",
    "from qiskit_algorithms.optimizers import SPSA\n",
    "from qiskit_optimization import QuadraticProgram\n",
    "from qiskit_optimization.converters import QuadraticProgramToQubo\n",
    "from qiskit_optimization.algorithms import MinimumEigenOptimizer\n",
    "\n",
    "# QUBO builder helper\n",
    "from docplex.mp.model import Model\n",
    "\n",
    "# Data fetch\n",
    "import yfinance as yf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45aa4190",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ===== CONFIG =====\n",
    "CFG = {\n",
    "    'tickers': ['AAPL','MSFT','GOOGL','AMZN','NVDA','META','TSLA','AMD','CRM','AVGO'],\n",
    "    'period': '1y',\n",
    "    'interval': '1d',\n",
    "    'risk_free': 0.02,\n",
    "    'K': 5,                     # cardinality for selection-mode\n",
    "    'bits_per_asset': 2,        # for discrete weights encoding (binary fixed-point)\n",
    "    'weight_step': 0.05,        # unary alternative step size (not used if binary)\n",
    "    'use_discrete_weights': False, # if True uses multi-bit weight encoding; else selection (0/1)\n",
    "    'max_weight': 0.5,          # cap per asset in discrete mode\n",
    "    'dinkelbach_iters': 4,\n",
    "    'p_list': [1,2], 'shots': 2048, 'seed': 123,\n",
    "    'shrink_leduit_wolf': True,\n",
    "    'bl_enabled': False,        # optional Black-Litterman\n",
    "    'sector_caps': {},         # e.g. {'Tech':([0,1,4],3)}\n",
    "    'prev_selection': None,     # list of 0/1 previous picks for turnover penalty\n",
    "    'lambda_ham': 0.1,          # turnover penalty strength\n",
    "    'transaction_cost': 0.001,  # per-dollar transaction cost (for turnover-aware Sharpe)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bee081a",
   "metadata": {},
   "source": [
    "\n",
    "## Ledoit–Wolf shrinkage (simple implementation)\n",
    "We compute the LW shrinkage target as the diagonal matrix and compute alpha following a basic Ledoit–Wolf closed form for small samples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f6b4b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def ledoit_wolf_shrinkage(Sigma_sample: np.ndarray, returns: np.ndarray):\n",
    "    # returns: T x n matrix of returns (daily)\n",
    "    n = Sigma_sample.shape[0]\n",
    "    T = returns.shape[0]\n",
    "    sample = Sigma_sample.copy()\n",
    "    mu = np.diag(sample).mean()\n",
    "    F = np.eye(n) * mu\n",
    "    # compute pi_hat\n",
    "    X = returns - returns.mean(axis=0, keepdims=True)\n",
    "    pi_hat = 0.0\n",
    "    for t in range(T):\n",
    "        xt = X[t:t+1].T @ X[t:t+1]\n",
    "        pi_hat += np.sum((xt - sample) ** 2)\n",
    "    pi_hat /= T\n",
    "    # rho_hat\n",
    "    rho_hat = np.sum((sample - F) ** 2)\n",
    "    # gamma\n",
    "    gamma = np.linalg.norm(sample - F, 'fro')**2\n",
    "    # alpha (shrinkage intensity)\n",
    "    kappa = (pi_hat - rho_hat) / gamma if gamma > 0 else 0.0\n",
    "    alpha = max(0.0, min(1.0, kappa / T))\n",
    "    Sigma_shrunk = (1 - alpha) * sample + alpha * F\n",
    "    return Sigma_shrunk, alpha\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8258433b",
   "metadata": {},
   "source": [
    "\n",
    "## Black–Litterman (optional)\n",
    "If enabled, we compute an implied prior from market caps or user-supplied prior and blend with views P, Q.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c0affb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def black_litterman(mu_prior: np.ndarray, Sigma: np.ndarray, P: Optional[np.ndarray], Q: Optional[np.ndarray],\n",
    "                    tau: float = 0.05, omega: Optional[np.ndarray] = None):\n",
    "    # Simple BL posterior mean (returns)\n",
    "    n = len(mu_prior)\n",
    "    if P is None or Q is None:\n",
    "        return mu_prior\n",
    "    if omega is None:\n",
    "        omega = np.diag(np.diag(P @ (tau * Sigma) @ P.T))\n",
    "    A = np.linalg.pinv(tau * Sigma)\n",
    "    middle = A + P.T @ np.linalg.pinv(omega) @ P\n",
    "    rhs = A @ mu_prior + P.T @ np.linalg.pinv(omega) @ Q\n",
    "    mu_bl = np.linalg.pinv(middle) @ rhs\n",
    "    return mu_bl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "921bc516",
   "metadata": {},
   "source": [
    "\n",
    "## Data fetch and preprocessing (annualize returns and covariance)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8b45ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_and_prepare(tickers, period='1y', interval='1d'):\n",
    "    df = yf.download(tickers, period=period, interval=interval, auto_adjust=True, progress=False)['Close']\n",
    "    if isinstance(df, pd.Series):\n",
    "        df = df.to_frame()\n",
    "    df = df.dropna(how='all').ffill().dropna(axis=1)\n",
    "    rets = df.pct_change().dropna()\n",
    "    mu_d = rets.mean().values\n",
    "    Sigma_d = rets.cov().values\n",
    "    mu = mu_d * 252.0\n",
    "    Sigma = Sigma_d * 252.0\n",
    "    return df, rets.values, mu, Sigma\n",
    "\n",
    "prices, rets_daily, mu, Sigma = fetch_and_prepare(CFG['tickers'], CFG['period'], CFG['interval'])\n",
    "n = len(mu)\n",
    "print('Tickers:', CFG['tickers'])\n",
    "print('mu (annual):', np.round(mu,4))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9770e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply Ledoit-Wolf shrinkage if enabled\n",
    "if CFG['shrink_leduit_wolf']:\n",
    "    Sigma_sh, alpha = ledoit_wolf_shrinkage(Sigma, rets_daily)\n",
    "    print('Ledoit-Wolf alpha:', round(alpha,5))\n",
    "    Sigma = Sigma_sh\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a07bd5f9",
   "metadata": {},
   "source": [
    "\n",
    "## Encoding options\n",
    "- **Selection mode**: x_i ∈ {0,1} — pick asset or not (equal weights or refine later)\n",
    "- **Discrete weights (binary fixed-point)**: use `bits_per_asset` per asset to encode weights up to `max_weight`.\n",
    "Note: discrete weights blow up qubit count: n * bits_per_asset qubits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008516e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def binary_encoding_vars(n, bits_per_asset):\n",
    "    # returns total bits and mapping asset->bit indices\n",
    "    total_bits = n * bits_per_asset\n",
    "    mapping = {i: list(range(i*bits_per_asset, (i+1)*bits_per_asset)) for i in range(n)}\n",
    "    return total_bits, mapping\n",
    "\n",
    "def weight_from_bits(y_bits: np.ndarray, mapping: Dict[int, List[int]], bits_per_asset: int, max_weight: float):\n",
    "    # interpret bits as unsigned integer and scale to [0, max_weight]\n",
    "    n = len(mapping)\n",
    "    w = np.zeros(n)\n",
    "    for i in range(n):\n",
    "        inds = mapping[i]\n",
    "        val = 0\n",
    "        for b_idx, bitpos in enumerate(inds):\n",
    "            val += int(y_bits[bitpos]) * (2**b_idx)\n",
    "        max_int = 2**bits_per_asset - 1\n",
    "        w[i] = (val / max_int) * max_weight if max_int>0 else 0.0\n",
    "    return w\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0943c970",
   "metadata": {},
   "source": [
    "\n",
    "## QUBO builder: supports selection mode or discrete-weight binary encoding.\n",
    "It includes penalties for cardinality, sector caps, and turnover/transaction cost.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9894a8f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_qubo_selection(mu, Sigma, rf, K, t_param, A_card, sector_caps, A_sec, x_prev, lambda_ham, trans_cost):\n",
    "    r = mu - rf\n",
    "    n = len(r)\n",
    "    mdl = Model('select_qubo')\n",
    "    x = mdl.binary_var_list(n, name='x')\n",
    "\n",
    "    lin = mdl.sum(r[i] * x[i] for i in range(n))\n",
    "    quad_risk = mdl.sum(Sigma[i,j] * x[i] * x[j] for i in range(n) for j in range(n))\n",
    "    obj = lin - (t_param / K) * quad_risk\n",
    "\n",
    "    # cardinality\n",
    "    sumx = mdl.sum(x)\n",
    "    obj -= A_card * (sumx - K) * (sumx - K)\n",
    "\n",
    "    # sector caps\n",
    "    for name, (idxs, cap) in sector_caps.items():\n",
    "        if len(idxs)==0: continue\n",
    "        sx = mdl.sum(x[i] for i in idxs)\n",
    "        obj -= A_sec * (sx - cap) * (sx - cap)\n",
    "\n",
    "    # turnover penalty (Hamming distance) and transaction cost approximation\n",
    "    if x_prev is not None:\n",
    "        for i in range(n):\n",
    "            prev = int(x_prev[i])\n",
    "            # penalize changes: cost ~ lambda_ham*(x_i + prev - 2 x_i * prev) and tx cost proportional\n",
    "            obj -= lambda_ham * (x[i] + prev - 2 * x[i] * prev)\n",
    "            if not prev and trans_cost>0:\n",
    "                # cost to buy: subtract trans_cost * expected weight approx (use equal weight approx)\n",
    "                obj -= trans_cost * (1.0/K) * x[i]\n",
    "    mdl.maximize(obj)\n",
    "    qp = QuadraticProgram()\n",
    "    qp = QuadraticProgram.from_docplex(mdl) if hasattr(QuadraticProgram, 'from_docplex') else QuadraticProgram()\n",
    "    # safe convert via qiskit_optimization.translators if needed\n",
    "    try:\n",
    "        from qiskit_optimization.translators import from_docplex_mp\n",
    "        qp = from_docplex_mp(mdl)\n",
    "    except Exception:\n",
    "        # fallback: directly build variables\n",
    "        pass\n",
    "    return qp\n",
    "\n",
    "def build_qubo_binary_weights(mu, Sigma, rf, bits_per_asset, max_weight, t_param, A_budget, budget_val, sector_caps, A_sec, x_prev, lambda_ham, trans_cost):\n",
    "    # Build QUBO over binary bits representing weights\n",
    "    n = len(mu)\n",
    "    total_bits, mapping = binary_encoding_vars(n, bits_per_asset)\n",
    "    mdl = Model('binary_weight_qubo')\n",
    "    y = mdl.binary_var_list(total_bits, name='y')\n",
    "\n",
    "    # map bits to weights symbolically: weight_i = (sum 2^b y_b) / (2^L -1) * max_weight\n",
    "    max_int = 2**bits_per_asset - 1\n",
    "    scale = max_weight / max_int if max_int>0 else 0.0\n",
    "\n",
    "    # linear return term: r^T w\n",
    "    r = mu - rf\n",
    "    lin = mdl.sum( r[i] * scale * mdl.sum( (2**(b_idx)) * y[b_idx_global] \n",
    "                                          for b_idx, b_idx_global in enumerate(mapping[i]) ) \n",
    "                  for i in range(n) )\n",
    "\n",
    "    # quadratic risk term: w^T Sigma w -> quadratic in y bits\n",
    "    quad = mdl.sum( (scale * (2**(b_idx)) * (scale * (2**(b_jdx)))) * Sigma[i,j] * y[b_idx_global] * y[b_jdx_global]\n",
    "                    for i in range(n) for j in range(n)\n",
    "                    for b_idx, b_idx_global in enumerate(mapping[i])\n",
    "                    for b_jdx, b_jdx_global in enumerate(mapping[j]) )\n",
    "\n",
    "    obj = lin - t_param * quad\n",
    "\n",
    "    # budget constraint: sum weights approx == budget_val (like 1.0)\n",
    "    # encode (sum_i w_i - budget_val)^2 penalty\n",
    "    sumw = mdl.sum( scale * mdl.sum((2**b_idx) * y[b_idx_global] for b_idx, b_idx_global in enumerate(mapping[i])) for i in range(n))\n",
    "    obj -= A_budget * (sumw - budget_val) * (sumw - budget_val)\n",
    "\n",
    "    # sector caps: approximate by bounding sum of bits in each sector (coarse)\n",
    "    for name, (idxs, cap) in sector_caps.items():\n",
    "        # convert cap in weights -> cap_bits approx\n",
    "        cap_bits = int(np.ceil(cap / max_weight * (2**bits_per_asset - 1))) * len(idxs)\n",
    "        sx = mdl.sum(y[b] for i in idxs for b in mapping[i])\n",
    "        obj -= A_sec * (sx - cap_bits) * (sx - cap_bits)\n",
    "\n",
    "    # turnover and txcost approximations (not exact)\n",
    "    if x_prev is not None:\n",
    "        # penalize changes on most-significant bit as proxy\n",
    "        for i in range(n):\n",
    "            prev = int(x_prev[i])\n",
    "            msb_idx = mapping[i][-1]\n",
    "            obj -= lambda_ham * ( y[msb_idx] + prev - 2 * y[msb_idx] * prev )\n",
    "    mdl.maximize(obj)\n",
    "    try:\n",
    "        from qiskit_optimization.translators import from_docplex_mp\n",
    "        qp = from_docplex_mp(mdl)\n",
    "    except Exception:\n",
    "        qp = QuadraticProgram()\n",
    "    return qp\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ecca66",
   "metadata": {},
   "source": [
    "\n",
    "## QAOA solver (Aer sampler) and Dinkelbach loop\n",
    "Note: we use QAOA as the inner solver for each Dinkelbach t parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730ce13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def qaoa_solve_qp(qp: QuadraticProgram, p_list, shots, seed):\n",
    "    qubo = QuadraticProgramToQubo().convert(qp)\n",
    "    sampler = Sampler(options={'seed':seed, 'shots':shots})\n",
    "    best=None; best_res=None\n",
    "    for p in p_list:\n",
    "        qaoa = QAOA(sampler=sampler, reps=int(p), optimizer=SPSA(maxiter=120, blocking=True))\n",
    "        solver = MinimumEigenOptimizer(qaoa)\n",
    "        try:\n",
    "            res = solver.solve(qubo)\n",
    "        except Exception as e:\n",
    "            print('QAOA solver failed:', e)\n",
    "            continue\n",
    "        # extract bits into vector\n",
    "        x = np.array([int(res.variables_dict[k]) for k in sorted(res.variables_dict.keys(), key=lambda s: int(s.split('_')[-1]))])\n",
    "        val = qubo.objective.evaluate(res.variables_dict)\n",
    "        cand={'x':x,'p':p,'energy':val,'raw':res}\n",
    "        if (best is None) or (val>best['energy']):\n",
    "            best=cand; best_res=res\n",
    "    return best, best_res\n",
    "\n",
    "def dinkelbach_qaoa_runner(mu, Sigma, rf, CFG):\n",
    "    use_discrete = CFG['use_discrete_weights']\n",
    "    n = len(mu)\n",
    "    # init t with greedy equal selection\n",
    "    x0 = baseline_greedy(mu, Sigma, CFG['K'], rf)['x']\n",
    "    w0 = equal_weights_from_x(x0)\n",
    "    r = mu - rf\n",
    "    t = float((r @ w0) / max(w0 @ Sigma @ w0, 1e-12))\n",
    "    best_overall = None; history=[]\n",
    "    lam_max = float(np.linalg.eigvalsh(Sigma).max())\n",
    "    for it in range(CFG['dinkelbach_iters']):\n",
    "        A_card = 10.0 * (t / CFG['K']) * lam_max\n",
    "        A_sec = 5.0 * (t / CFG['K']) * lam_max\n",
    "        if not use_discrete:\n",
    "            qp = build_qubo_selection(mu, Sigma, rf, CFG['K'], t, A_card, CFG['sector_caps'], A_sec, CFG['prev_selection'], CFG['lambda_ham'], CFG['transaction_cost'])\n",
    "        else:\n",
    "            qp = build_qubo_binary_weights(mu, Sigma, rf, CFG['bits_per_asset'], CFG['max_weight'], t, A_card, 1.0, CFG['sector_caps'], A_sec, CFG['prev_selection'], CFG['lambda_ham'], CFG['transaction_cost'])\n",
    "        best, raw = qaoa_solve_qp(qp, CFG['p_list'], CFG['shots'], CFG['seed'])\n",
    "        if best is None:\n",
    "            print('No valid QAOA result at iter', it); break\n",
    "        x = best['x']\n",
    "        # for discrete mode, map bits->weights; for selection mode, equal-weight then refine\n",
    "        if not use_discrete:\n",
    "            w_eq = equal_weights_from_x(x)\n",
    "            numer = float((mu - rf) @ w_eq); denom = float(w_eq @ Sigma @ w_eq)\n",
    "            s_eq = sharpe(w_eq, mu, Sigma, rf)\n",
    "            t_new = numer / max(denom, 1e-12)\n",
    "        else:\n",
    "            # map bits to weights and compute sharpe\n",
    "            total_bits, mapping = binary_encoding_vars(n, CFG['bits_per_asset'])\n",
    "            w = weight_from_bits(x, mapping, CFG['bits_per_asset'], CFG['max_weight'])\n",
    "            # normalize to sum to 1 if possible\n",
    "            if w.sum() > 0:\n",
    "                w = w / w.sum()\n",
    "            else:\n",
    "                w = np.zeros(n)\n",
    "            w_eq = w; s_eq = sharpe(w_eq, mu, Sigma, rf)\n",
    "            numer = float((mu - rf) @ w_eq); denom = float(w_eq @ Sigma @ w_eq)\n",
    "            t_new = numer / max(denom, 1e-12)\n",
    "        history.append({'iter':it, 't':t, 't_new':t_new, 'x':x, 'w_eq':w_eq, 'sharpe_eq':s_eq})\n",
    "        if best_overall is None or s_eq > best_overall['sharpe_eq']:\n",
    "            best_overall = history[-1]\n",
    "        if abs(t_new - t) < 1e-3:\n",
    "            t = t_new; break\n",
    "        t = t_new\n",
    "    return best_overall, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b9f2c03",
   "metadata": {},
   "source": [
    "\n",
    "## Helper functions (baselines & refinement)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14b67fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sharpe(weights, mu, Sigma, rf):\n",
    "    port_ret = float(weights @ mu)\n",
    "    port_var = float(weights @ Sigma @ weights)\n",
    "    port_vol = math.sqrt(max(port_var, 1e-12))\n",
    "    return (port_ret - rf) / (port_vol if port_vol>0 else 1e-12)\n",
    "\n",
    "def equal_weights_from_x(x):\n",
    "    idx = np.flatnonzero(x)\n",
    "    if len(idx)==0: return None\n",
    "    w = np.zeros_like(x, dtype=float)\n",
    "    w[idx] = 1.0/len(idx)\n",
    "    return w\n",
    "\n",
    "def subset_tangency(mu, Sigma, rf, x):\n",
    "    S = np.flatnonzero(x)\n",
    "    if len(S)==0: return None\n",
    "    Sigma_SS = Sigma[np.ix_(S,S)]; r_S = mu[S] - rf\n",
    "    inv = np.linalg.pinv(Sigma_SS)\n",
    "    w_S = inv @ r_S\n",
    "    denom = np.ones(len(S)) @ w_S\n",
    "    if abs(denom)<1e-12: return None\n",
    "    w_S = w_S / denom\n",
    "    w = np.zeros(len(mu)); w[S]=w_S\n",
    "    return w\n",
    "\n",
    "def baseline_greedy(mu, Sigma, K, rf, lamb=4.0):\n",
    "    diag = np.diag(Sigma); r = mu - rf; scores = r - lamb * diag\n",
    "    pick = np.argsort(scores)[::-1][:K]\n",
    "    x = np.zeros_like(mu, dtype=int); x[pick]=1\n",
    "    w = equal_weights_from_x(x); s = sharpe(w, mu, Sigma, rf)\n",
    "    return {'name':'greedy','x':x,'w':w,'sharpe':s}\n",
    "\n",
    "def baseline_tangency(mu, Sigma, rf):\n",
    "    r = mu - rf; inv = np.linalg.pinv(Sigma); w = inv @ r\n",
    "    denom = np.ones_like(r) @ w\n",
    "    if abs(denom)<1e-12: return {'name':'tangency','w':None,'sharpe':float('nan')}\n",
    "    w = w / denom; return {'name':'tangency','w':w,'sharpe':sharpe(w, mu, Sigma, rf)}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d49a41f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Run baselines\n",
    "greedy_res = baseline_greedy(mu, Sigma, CFG['K'], CFG['risk_free'])\n",
    "tangency_res = baseline_tangency(mu, Sigma, CFG['risk_free'])\n",
    "print('Greedy Sharpe:', round(greedy_res['sharpe'],4))\n",
    "print('Tangency Sharpe:', round(tangency_res['sharpe'],4))\n",
    "\n",
    "# Run the Dinkelbach QAOA runner\n",
    "best_overall, history = dinkelbach_qaoa_runner(mu, Sigma, CFG['risk_free'], CFG)\n",
    "print('\\nBest QAOA equal-weight Sharpe (from candidate):', round(best_overall['sharpe_eq'],4))\n",
    "print('Selected indices:', np.flatnonzero(best_overall['x']).tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0239f679",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Refinement for selection mode (tangency)\n",
    "w_refined = subset_tangency(mu, Sigma, CFG['risk_free'], best_overall['x'])\n",
    "s_refined = sharpe(w_refined, mu, Sigma, CFG['risk_free'])\n",
    "print('Refined Sharpe:', round(s_refined,4))\n",
    "\n",
    "# Show results summary\n",
    "labels = ['Greedy (eq-w)', 'QAOA (eq-w)', 'QAOA + Refine', 'Tangency (no card)']\n",
    "values = [greedy_res['sharpe'], best_overall['sharpe_eq'], s_refined, tangency_res['sharpe']]\n",
    "for L,V in zip(labels, values):\n",
    "    print(f'{L:>18}: {V:.4f}')\n",
    "\n",
    "plt.figure(figsize=(7,4)); plt.bar(labels, values); plt.ylabel('Sharpe'); plt.title('Sharpe Comparison'); plt.show()\n",
    "\n",
    "# Print final weights\n",
    "sel = np.flatnonzero(best_overall['x']).tolist()\n",
    "print('Selected tickers:', [CFG['tickers'][i] for i in sel])\n",
    "print('\\nRefined weights:')\n",
    "for i,t in enumerate(CFG['tickers']):\n",
    "    if w_refined[i] != 0:\n",
    "        print(f' {t}: {w_refined[i]:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b6dd32",
   "metadata": {},
   "source": [
    "\n",
    "## Notes on XY-mixers and warm-starts\n",
    "- Implementing custom mixers (XY mixer) requires building parameterized QAOA-like circuits that preserve Hamming-weight subspace (for cardinality constraints). Qiskit's high-level QAOA API does not expose custom mixers directly; you'd implement a custom variational ansatz using `QuantumCircuit` and `VQE`/`Estimator` primitives or a low-level QAOA builder.\n",
    "- Warm-starting: use greedy solution to bias initial angles or to modify mixer Hamiltonian to prefer certain qubits. Implement by seeding classical optimizer or appending small local rotations toward greedy state prior to QAOA layers.\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
